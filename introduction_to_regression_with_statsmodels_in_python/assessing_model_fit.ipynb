{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient of determination (R-squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination is a measure of how well a linear regression line fits the observed values. Is definded as the proportion of the variance in the response variable that is predictable from the explanatory variable.\n",
    "\n",
    "For simple linear regression, the interpretation of the coefficient of determination is simply **the correlation between the explanatory and response variable, squared**.\n",
    "\n",
    "It takes values from 0 to 1. \n",
    "* An coefficient of determination equal to 0 implies a useless model.\n",
    "* An coefficient of determination equal to 1 corresponds to a perfect model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual standard error (RSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual standard error ($\\text{RSE}$) is a measure of the typical size of the residuals. Equivalently, it's a measure of how wrong you can expect predictions to be.\n",
    "\n",
    "$\\displaystyle{\\text{RSE} = \\sqrt{\\frac{1}{\\eta}\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2}}$ , \n",
    "\n",
    "where $\\bar{y}_i^2$ and $y_i$ are the predicted and real value, respectively,\n",
    "\n",
    "and $\\eta$ is the number of degrees of freedom: the number of observations minus the number of model coefficients. \n",
    "\n",
    "\n",
    "\n",
    "The $\\text{RSE}$ has the same units as the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is another metric of accuracy of a linear regression model. In terms of the $\\text{RSE}$ is defined as\n",
    "\n",
    "$\\displaystyle{\\text{MSE} = \\text{RSE}^2}$,\n",
    "\n",
    "$\\displaystyle{\\text{MSE} = \\frac{1}{\\eta}\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root-mean-square error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a metric similar to $\\text{RSE}$, but you use the number of observations $n$ instead of $\\eta$.\n",
    "\n",
    "If you want to compare the accuracy of different models, generally you should use the $\\text{RSE}$ of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle{\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\bar{y}_i)^2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals vs. fitted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a linear regression model is good fit, then the residuals are approximately normally distributed, with mean zero. \n",
    "\n",
    "This graph is useful to identifying whether the residual values tend to grow or decrease as the fitted values increase. If our model is good, the residual values must be all around zero and should not have a tendecy to increase or decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of graph shows how well our residuals fit a normal distribution. If they do, our data points must be near to a straight line with a slope of $0.5$ and with intercept $0$.\n",
    "\n",
    "On the x-axis the points correspond to quantiles from the normal distribution. On the y-axis the points correspond to the quantiles derived from you dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale-location plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the square root of the standarized residuals versus the fitted values. It is useful to identifying wether the residuals sizes are randomly distributed as the fitted values increases. That is the expected behavior is the data fits to a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers, leverage and influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created a linear model for out dataset, there are two ways to identify outliers within it:\n",
    "\n",
    "* Find **extreme values** for the **explanatory variable**.\n",
    "* Find the **points far away** from the **model line**.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage measures **how unusual or extreme the explanatory variables are** for each observation **High leverage** means that the explanatory variable has **values that are different** from other points in the dataset. \n",
    "\n",
    "In the case of **simple linear regression**, where there is only one explanatory value, this typically means values with a very **high or very low explanatory value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influence measures **how much a model would change if each observation was left out of the model** calculations, one at a time. That is, it measures how different the prediction line would look if you would run a linear regression on all data points except that point, compared to running a linear regression on the whole dataset. \n",
    "\n",
    "The **standard metric for influence** is **Cook's distance**, which calculates influence **based on the residual size and the leverage of the point**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Influence measures how much a model would change if each observation was left out of the model calculations, one at a time. That is, it measures how different the prediction line would look if you would run a linear regression on all data points except that point, compared to running a linear regression on the whole dataset. It depends on the value of the data and its leverage. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4f0d65552bc075afe9f9c8bc4ef141871ed903055cde9c4cb3d67442ed89dff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
